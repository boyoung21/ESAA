{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boyoung21/ESAA/blob/main/09_12_%EC%84%B8%EC%85%98_%EB%AA%A8%EB%8D%B8%ED%9B%88%EB%A0%A8_%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **모델 훈련 연습 문제**\n",
        "___\n",
        "- 출처 : 핸즈온 머신러닝 Ch04 연습문제 1, 5, 9, 10\n",
        "- 개념 문제의 경우 텍스트 셀을 추가하여 정답을 적어주세요."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "수백만 개의 특성일 때 선형 회귀 모형을 사용하면 데이터의 복잡한 특성을 제대로 반영하지 못할 확률이 높다. polynomial features를 사용하여 다항회귀를 적용한다면, 데이터의 복잡성을 어느 정도는 반영할 수 있을 것이다. 그러나 이는 그만큼 시간적으로 소요가 클 것으로 예상된다. 또는 릿지, 라쏘, 엘라스틱넷처럼 규제를 사용하는 회귀 알고리즘을 사용한다면 특성의 중요도에 따라 가중치를 다르게 두기 때문에 복잡성을 줄일 수 있을 것이다. 또, 확률적 경사 하강법이나 미니 배치 하강법 역시 메모리 사용량이나 모델에 소요되는 시간을 줄이는 데 효과적일 것이다. 데이터의 특성을 고려하여 해당 알고리즘 중에 선택한다면, 단순한 선형 회귀보다 더 나은 예측 성능을 보일 것이다."
      ],
      "metadata": {
        "id": "jRwAtN-YSa_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?**\n",
        "___\n",
        "\n",
        "검증 오차가 하강할수록 모델의 일반화 성능이 좋다고 할 수 있는데, 높아지고 있다는 것은 오히려 모델이 훈련 세트에 과적합되었음을 의미한다. 이는 좋은 모델이 아니기 때문에 모델의 파라미터를 조정하여 해결하거나 다른 알고리즘을 사용하는 방법이 문제를 해결하는 데 도움이 될 것이다. 또는, 어느 수준까지는 감소하다가 다시 검증 오차가 올라가는 것이라면 조기 종료를 사용하여 검증 오차가 최소일 때 훈련을 종료하는 방법을 사용할 수 있을 것이다."
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 릿지 회귀를 사용했을 때 훈련 오차가 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 $\\alpha$를 증가시켜야 할까요 아니면 줄여야 할까요?**\n",
        "___"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "릿지 회귀를 적용했을 때 훈련 오차와 검증 오차가 거의 비슷하고, 동시에 두 값 모두 높게 나타난다면 이는 모델이 데이터의 패턴을 충분히 학습하지 못한 상황이다. 즉, 과적합 문제가 아닌 과소적합으로 인한 높은 편향이 원인이라고 볼 수 있다. 릿지 회귀에서 규제 강도 alpha는 값을 크게 설정하면 가중치가 강하게 억제되어 모델이 단순해지고, 이로 인해 편향이 증가한다. 반대로 값을 줄이면 규제가 완화되어 모델이 더 많은 복잡성을 반영할 수 있으므로 편향이 낮아질 수 있다.따라서, 이 경우에는 높은 편향이 문제이므로 값을 줄이는 것이 적절한 대응이다."
      ],
      "metadata": {
        "id": "HU4CjtauUhPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 다음과 같이 사용해야 하는 이유는?**\n",
        "___\n",
        "- 평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀\n",
        "- 릿지 회귀 대신 라쏘 회귀\n",
        "- 라쏘 회귀 대신 엘라스틱넷"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 평범한 선형 회귀 대신 릿지 회귀를 쓰는 이유는, 특성 수가 많거나 다중공선성이 심한 경우에 평범한 선형 회귀의 예측력이 떨어지기 때문이다. 이런 상황에서 릿지 회귀는 규제를 통해 계수에 각기 다른 가중치를 부여하므로 모델의 과적합을 방지할 수 있다.\n",
        "\n",
        "2. 릿지 회귀 대신 라쏘 회귀를 쓰는 것은, 특성이 많은 경우 라쏘 회귀가 더 효율적이기 때문이다. 릿지 회귀는 특성마다 가중치를 다르게 두지만 계수를 0으로 만들지는 않기에 모든 특성을 그대로 사용하게 된다. 이는 불필요한 변수로 인해 오히려 모델 예측력의 저하로 이어질 수 있다. 반면 라쏘 회귀는 불필요한 특성의 계수를 아예 0으로 만들어 버리기에 모델을 간결하게 하고, 중요한 변수만 선별하여 예측에 반영한다.\n",
        "\n",
        "3.그러나 라쏘 회귀는 다중공선성이 강할 때 한쪽 특성만 선택하는 등 중요한 변수를 오히려 반영하지 못하게 되는 경우가 존재한다. 엘라스틱넷은 릿지와 라쏘의 특성을 모두 반영한다는 점에서 라쏘보다 더 유연하게 변수를 반영한다."
      ],
      "metadata": {
        "id": "C7IszLGIU4s5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **추가) 조기 종료를 사용한 배치 경사 하강법으로 iris 데이터를 활용해 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요)**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QIZpOEYJVIAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 준비\n",
        "iris = load_iris()\n",
        "X = iris[\"data\"][:, (2,3)]   # 꽃잎 길이, 꽃잎 너비\n",
        "y = iris[\"target\"]\n",
        "y_onehot = np.eye(3)[y]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# 유틸 함수\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - z.max(axis=1, keepdims=True))\n",
        "    return exp_z / exp_z.sum(axis=1, keepdims=True)\n",
        "\n",
        "def loss(y, p):\n",
        "    return -np.mean(np.sum(y*np.log(p+1e-15), axis=1))\n",
        "\n",
        "# 파라미터\n",
        "W = np.zeros((X.shape[1], 3))\n",
        "b = np.zeros((1, 3))\n",
        "lr, patience, best, wait = 0.1, 20, 1e9, 0\n",
        "\n",
        "# 학습\n",
        "for epoch in range(5000):\n",
        "    p = softmax(X_train @ W + b)\n",
        "    W -= lr * (X_train.T @ (p - y_train)) / len(X_train)\n",
        "    b -= lr * (p - y_train).mean(axis=0, keepdims=True)\n",
        "\n",
        "    val_loss = loss(y_val, softmax(X_val @ W + b))\n",
        "    if val_loss < best:\n",
        "        best, bestW, bestb, wait = val_loss, W.copy(), b.copy(), 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "# 예측 & 정확도\n",
        "pred = np.argmax(softmax(X_val @ bestW + bestb), axis=1)\n",
        "acc = (pred == np.argmax(y_val, axis=1)).mean()\n",
        "print(\"Validation Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "8pXDQ_fU8Nz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20f35f7-306d-4ffa-a348-9552145557e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}